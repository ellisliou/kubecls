apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-04-06T04:29:48Z"
    generateName: nginx-app-5d47bf8b9-
    labels:
      app: nginx-app
      pod-template-hash: 5d47bf8b9
    name: nginx-app-5d47bf8b9-rxgsq
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nginx-app-5d47bf8b9
      uid: 4599239f-d8dd-48de-b1de-73811b2923f8
    resourceVersion: "72553"
    uid: 81e32925-b6ab-4c22-a824-b2d7bcf5b5e2
  spec:
    containers:
    - image: nginx
      imagePullPolicy: Always
      name: nginx
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-gggmv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k8s-node1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-gggmv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:54:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:54:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://4447d1cef6a909f9836ddd8f22cb16f1d61606b52d8b3b7d4b5d208cb39e2f9b
      image: docker.io/library/nginx:latest
      imageID: docker.io/library/nginx@sha256:2ab30d6ac53580a6db8b657abf0f68d75360ff5cc1670a85acb5bd85ba1b19c0
      lastState: {}
      name: nginx
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-04-06T05:54:13Z"
    hostIP: 192.168.118.239
    phase: Running
    podIP: 10.244.1.7
    podIPs:
    - ip: 10.244.1.7
    qosClass: BestEffort
    startTime: "2023-04-06T05:53:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-04-06T04:29:48Z"
    generateName: nginx-app-5d47bf8b9-
    labels:
      app: nginx-app
      pod-template-hash: 5d47bf8b9
    name: nginx-app-5d47bf8b9-slzcx
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nginx-app-5d47bf8b9
      uid: 4599239f-d8dd-48de-b1de-73811b2923f8
    resourceVersion: "72568"
    uid: e9d502ee-8350-4eb9-8d01-df8a5fa9f78f
  spec:
    containers:
    - image: nginx
      imagePullPolicy: Always
      name: nginx
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dqxbw
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: k8s-node1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-dqxbw
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:54:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:54:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://2f78d815c37e384005540363e4e65833f9f8133b927c145492a0214c2c2a5f19
      image: docker.io/library/nginx:latest
      imageID: docker.io/library/nginx@sha256:2ab30d6ac53580a6db8b657abf0f68d75360ff5cc1670a85acb5bd85ba1b19c0
      lastState: {}
      name: nginx
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-04-06T05:54:17Z"
    hostIP: 192.168.118.239
    phase: Running
    podIP: 10.244.1.6
    podIPs:
    - ip: 10.244.1.6
    qosClass: BestEffort
    startTime: "2023-04-06T05:53:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-03-14T08:51:44Z"
    generateName: kube-flannel-ds-
    labels:
      app: flannel
      controller-revision-hash: df8594f4d
      pod-template-generation: "1"
      tier: node
    name: kube-flannel-ds-5dn9b
    namespace: kube-flannel
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-flannel-ds
      uid: af9ab7d5-9820-403b-84fa-3935bef0dedb
    resourceVersion: "72518"
    uid: 7e3806cf-e5bb-45fc-aeab-e11ae0c7712d
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - k8s-node1
    containers:
    - args:
      - --ip-masq
      - --kube-subnet-mgr
      command:
      - /opt/bin/flanneld
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: EVENT_QUEUE_DEPTH
        value: "5000"
      image: docker.io/flannel/flannel:v0.21.3
      imagePullPolicy: IfNotPresent
      name: kube-flannel
      resources:
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /run/flannel
        name: run
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tbj7n
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - args:
      - -f
      - /flannel
      - /opt/cni/bin/flannel
      command:
      - cp
      image: docker.io/flannel/flannel-cni-plugin:v1.1.2
      imagePullPolicy: IfNotPresent
      name: install-cni-plugin
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-plugin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tbj7n
        readOnly: true
    - args:
      - -f
      - /etc/kube-flannel/cni-conf.json
      - /etc/cni/net.d/10-flannel.conflist
      command:
      - cp
      image: docker.io/flannel/flannel:v0.21.3
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tbj7n
        readOnly: true
    nodeName: k8s-node1
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: flannel
    serviceAccountName: flannel
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /run/flannel
        type: ""
      name: run
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-plugin
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni
    - configMap:
        defaultMode: 420
        name: kube-flannel-cfg
      name: flannel-cfg
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - name: kube-api-access-tbj7n
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:52:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:52:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:52:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:51:44Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://99f32f2c77657edc578132903681ad321eec04e9739300f29a17ca00a6b13d55
      image: docker.io/flannel/flannel:v0.21.3
      imageID: docker.io/flannel/flannel@sha256:2947963f52c22f2df17ba21e47839ad4b9123fb5545784c7922e8264e673268c
      lastState: {}
      name: kube-flannel
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-03-14T08:52:09Z"
    hostIP: 192.168.118.239
    initContainerStatuses:
    - containerID: cri-o://29cdc299a7691e1d0326a1f9d6d92b9312ddcfb2d74299ac65e2a43ac0aad7b3
      image: docker.io/flannel/flannel-cni-plugin:v1.1.2
      imageID: docker.io/flannel/flannel-cni-plugin@sha256:bf4b62b131666d040f35a327d906ee5a3418280b68a88d9b9c7e828057210443
      lastState: {}
      name: install-cni-plugin
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://29cdc299a7691e1d0326a1f9d6d92b9312ddcfb2d74299ac65e2a43ac0aad7b3
          exitCode: 0
          finishedAt: "2023-03-14T08:51:55Z"
          reason: Completed
          startedAt: "2023-03-14T08:51:55Z"
    - containerID: cri-o://bf804d336d0b0bd7c4d21e3660c5aced81f9722935c8c70bfabed0527c7d849d
      image: docker.io/flannel/flannel:v0.21.3
      imageID: docker.io/flannel/flannel@sha256:2947963f52c22f2df17ba21e47839ad4b9123fb5545784c7922e8264e673268c
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: cri-o://bf804d336d0b0bd7c4d21e3660c5aced81f9722935c8c70bfabed0527c7d849d
          exitCode: 0
          finishedAt: "2023-03-14T08:52:09Z"
          reason: Completed
          startedAt: "2023-03-14T08:52:09Z"
    phase: Running
    podIP: 192.168.118.239
    podIPs:
    - ip: 192.168.118.239
    qosClass: Burstable
    startTime: "2023-03-14T08:51:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-03-14T08:51:44Z"
    generateName: kube-flannel-ds-
    labels:
      app: flannel
      controller-revision-hash: df8594f4d
      pod-template-generation: "1"
      tier: node
    name: kube-flannel-ds-lqpnh
    namespace: kube-flannel
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-flannel-ds
      uid: af9ab7d5-9820-403b-84fa-3935bef0dedb
    resourceVersion: "72430"
    uid: b36b3c19-8737-4a61-8803-78f64347ba33
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - k8s-master
    containers:
    - args:
      - --ip-masq
      - --kube-subnet-mgr
      command:
      - /opt/bin/flanneld
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: EVENT_QUEUE_DEPTH
        value: "5000"
      image: docker.io/flannel/flannel:v0.21.3
      imagePullPolicy: IfNotPresent
      name: kube-flannel
      resources:
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /run/flannel
        name: run
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-75sms
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - args:
      - -f
      - /flannel
      - /opt/cni/bin/flannel
      command:
      - cp
      image: docker.io/flannel/flannel-cni-plugin:v1.1.2
      imagePullPolicy: IfNotPresent
      name: install-cni-plugin
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-plugin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-75sms
        readOnly: true
    - args:
      - -f
      - /etc/kube-flannel/cni-conf.json
      - /etc/cni/net.d/10-flannel.conflist
      command:
      - cp
      image: docker.io/flannel/flannel:v0.21.3
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-75sms
        readOnly: true
    nodeName: k8s-master
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: flannel
    serviceAccountName: flannel
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /run/flannel
        type: ""
      name: run
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-plugin
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni
    - configMap:
        defaultMode: 420
        name: kube-flannel-cfg
      name: flannel-cfg
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - name: kube-api-access-75sms
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:52:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:51:44Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://6cd5c1e787c4cb44924a56070d359affdd40ee8a89ca9852a0ce608ff7912418
      image: docker.io/flannel/flannel:v0.21.3
      imageID: docker.io/flannel/flannel@sha256:2947963f52c22f2df17ba21e47839ad4b9123fb5545784c7922e8264e673268c
      lastState: {}
      name: kube-flannel
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2023-04-06T05:53:24Z"
    hostIP: 192.168.118.238
    initContainerStatuses:
    - containerID: cri-o://0eb1356a66d954858ba1954fcfac630a612d26e3d11f3289951245ce601739b0
      image: docker.io/flannel/flannel-cni-plugin:v1.1.2
      imageID: docker.io/flannel/flannel-cni-plugin@sha256:bf4b62b131666d040f35a327d906ee5a3418280b68a88d9b9c7e828057210443
      lastState: {}
      name: install-cni-plugin
      ready: true
      restartCount: 2
      state:
        terminated:
          containerID: cri-o://0eb1356a66d954858ba1954fcfac630a612d26e3d11f3289951245ce601739b0
          exitCode: 0
          finishedAt: "2023-04-06T05:53:18Z"
          reason: Completed
          startedAt: "2023-04-06T05:53:18Z"
    - containerID: cri-o://35f866685755d4150814c00c7895ae6c2f3df8aac0f986c064e5fbc09dbafbb7
      image: docker.io/flannel/flannel:v0.21.3
      imageID: docker.io/flannel/flannel@sha256:2947963f52c22f2df17ba21e47839ad4b9123fb5545784c7922e8264e673268c
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 2
      state:
        terminated:
          containerID: cri-o://35f866685755d4150814c00c7895ae6c2f3df8aac0f986c064e5fbc09dbafbb7
          exitCode: 0
          finishedAt: "2023-04-06T05:53:21Z"
          reason: Completed
          startedAt: "2023-04-06T05:53:21Z"
    phase: Running
    podIP: 192.168.118.238
    podIPs:
    - ip: 192.168.118.238
    qosClass: Burstable
    startTime: "2023-03-14T08:51:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-03-14T08:32:11Z"
    generateName: coredns-787d4945fb-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 787d4945fb
    name: coredns-787d4945fb-g6mgj
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-787d4945fb
      uid: ced94e81-f902-48f1-a591-c9b501fc6969
    resourceVersion: "72447"
    uid: f2269da7-3e11-4465-91cc-2fb81c7256c0
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.9.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hk2kt
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: k8s-master
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-hk2kt
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:32:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:32Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:32Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:32:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://015c598ecc7a66258c920ab8029fc38e35db744606bd726c5a4ee9c9749f98d5
      image: registry.k8s.io/coredns/coredns:v1.9.3
      imageID: registry.k8s.io/coredns/coredns@sha256:8e352a029d304ca7431c6507b56800636c321cb52289686a581ab70aaa8a2e2a
      lastState: {}
      name: coredns
      ready: true
      restartCount: 184
      started: true
      state:
        running:
          startedAt: "2023-04-06T05:53:30Z"
    hostIP: 192.168.118.238
    phase: Running
    podIP: 10.244.0.4
    podIPs:
    - ip: 10.244.0.4
    qosClass: Burstable
    startTime: "2023-03-14T08:32:11Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-03-14T08:32:11Z"
    generateName: coredns-787d4945fb-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 787d4945fb
    name: coredns-787d4945fb-vxcvp
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-787d4945fb
      uid: ced94e81-f902-48f1-a591-c9b501fc6969
    resourceVersion: "72455"
    uid: b15b7fc5-929c-4a1d-8651-624b19784548
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.9.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tdhmh
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: k8s-master
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-tdhmh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:32:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:34Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:34Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:32:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://c019721637549419b8178770e88a4cbf2047cc7643b1658c964471539e45ad09
      image: registry.k8s.io/coredns/coredns:v1.9.3
      imageID: registry.k8s.io/coredns/coredns@sha256:8e352a029d304ca7431c6507b56800636c321cb52289686a581ab70aaa8a2e2a
      lastState: {}
      name: coredns
      ready: true
      restartCount: 184
      started: true
      state:
        running:
          startedAt: "2023-04-06T05:53:33Z"
    hostIP: 192.168.118.238
    phase: Running
    podIP: 10.244.0.5
    podIPs:
    - ip: 10.244.0.5
    qosClass: Burstable
    startTime: "2023-03-14T08:32:11Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/etcd.advertise-client-urls: https://192.168.118.238:2379
      kubernetes.io/config.hash: c178356678165c147428a99285e3750c
      kubernetes.io/config.mirror: c178356678165c147428a99285e3750c
      kubernetes.io/config.seen: "2023-03-14T16:31:45.974304981+08:00"
      kubernetes.io/config.source: file
    creationTimestamp: "2023-03-14T08:31:56Z"
    labels:
      component: etcd
      tier: control-plane
    name: etcd-k8s-master
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: k8s-master
      uid: 73b10b46-027c-4c34-97c3-caacea2fbd8e
    resourceVersion: "72395"
    uid: 333f0bc1-6edd-404e-9673-65f4ed92574f
  spec:
    containers:
    - command:
      - etcd
      - --advertise-client-urls=https://192.168.118.238:2379
      - --cert-file=/etc/kubernetes/pki/etcd/server.crt
      - --client-cert-auth=true
      - --data-dir=/var/lib/etcd
      - --experimental-initial-corrupt-check=true
      - --experimental-watch-progress-notify-interval=5s
      - --initial-advertise-peer-urls=https://192.168.118.238:2380
      - --initial-cluster=k8s-master=https://192.168.118.238:2380
      - --key-file=/etc/kubernetes/pki/etcd/server.key
      - --listen-client-urls=https://127.0.0.1:2379,https://192.168.118.238:2379
      - --listen-metrics-urls=http://127.0.0.1:2381
      - --listen-peer-urls=https://192.168.118.238:2380
      - --name=k8s-master
      - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
      - --peer-client-cert-auth=true
      - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
      - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      - --snapshot-count=10000
      - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      image: registry.k8s.io/etcd:3.5.6-0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health?exclude=NOSPACE&serializable=true
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /health?serializable=false
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/etcd
        name: etcd-data
      - mountPath: /etc/kubernetes/pki/etcd
        name: etcd-certs
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8s-master
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki/etcd
        type: DirectoryOrCreate
      name: etcd-certs
    - hostPath:
        path: /var/lib/etcd
        type: DirectoryOrCreate
      name: etcd-data
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:52:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:52:56Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:52:56Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:52:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://0825db2241bcaa2fde47ef5cbf5649f9a7f3e15e4d557fa0674f717a00c9be04
      image: registry.k8s.io/etcd:3.5.6-0
      imageID: registry.k8s.io/etcd@sha256:b0fdb657c0bd10d8c96ed2ce762842384709a9fc54d532220d5252f1f99b4d1d
      lastState: {}
      name: etcd
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2023-04-06T05:52:36Z"
    hostIP: 192.168.118.238
    phase: Running
    podIP: 192.168.118.238
    podIPs:
    - ip: 192.168.118.238
    qosClass: Burstable
    startTime: "2023-04-06T05:52:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 192.168.118.238:6443
      kubernetes.io/config.hash: 0dd0aa3123aebcb32b7ef902fee79336
      kubernetes.io/config.mirror: 0dd0aa3123aebcb32b7ef902fee79336
      kubernetes.io/config.seen: "2023-03-14T16:31:59.547598998+08:00"
      kubernetes.io/config.source: file
    creationTimestamp: "2023-03-14T08:32:00Z"
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-k8s-master
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: k8s-master
      uid: 73b10b46-027c-4c34-97c3-caacea2fbd8e
    resourceVersion: "72401"
    uid: 5258e8ae-728a-424a-abbc-1d01f13b031c
  spec:
    containers:
    - command:
      - kube-apiserver
      - --advertise-address=192.168.118.238
      - --allow-privileged=true
      - --authorization-mode=Node,RBAC
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --enable-admission-plugins=NodeRestriction
      - --enable-bootstrap-token-auth=true
      - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
      - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
      - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
      - --etcd-servers=https://127.0.0.1:2379
      - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      - --requestheader-allowed-names=front-proxy-client
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --secure-port=6443
      - --service-account-issuer=https://kubernetes.default.svc.cluster.local
      - --service-account-key-file=/etc/kubernetes/pki/sa.pub
      - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      image: registry.k8s.io/kube-apiserver:v1.26.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 192.168.118.238
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: 192.168.118.238
          path: /readyz
          port: 6443
          scheme: HTTPS
        periodSeconds: 1
        successThreshold: 1
        timeoutSeconds: 15
      resources:
        requests:
          cpu: 250m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 192.168.118.238
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/pki
        name: etc-pki
        readOnly: true
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8s-master
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: etc-pki
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-03-17T02:49:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:20Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:20Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-03-17T02:49:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://8d6fac3784a761805c4f71f97ad586604c2f4207e849215dae19af62231a070a
      image: registry.k8s.io/kube-apiserver:v1.26.2
      imageID: registry.k8s.io/kube-apiserver@sha256:0f03b93af45f39704b7da175db31e20da63d2ab369f350e59de8cbbef9d703e0
      lastState: {}
      name: kube-apiserver
      ready: true
      restartCount: 22
      started: true
      state:
        running:
          startedAt: "2023-04-06T05:52:35Z"
    hostIP: 192.168.118.238
    phase: Running
    podIP: 192.168.118.238
    podIPs:
    - ip: 192.168.118.238
    qosClass: Burstable
    startTime: "2023-03-17T02:49:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: aaed99a3c0837f49dfc7b411d5c7b5be
      kubernetes.io/config.mirror: aaed99a3c0837f49dfc7b411d5c7b5be
      kubernetes.io/config.seen: "2023-03-14T16:31:59.547600977+08:00"
      kubernetes.io/config.source: file
    creationTimestamp: "2023-03-14T08:32:00Z"
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-k8s-master
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: k8s-master
      uid: 73b10b46-027c-4c34-97c3-caacea2fbd8e
    resourceVersion: "72397"
    uid: e9dc324f-7b1c-42d5-baa0-66d14aedc190
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --allocate-node-cidrs=true
      - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --bind-address=127.0.0.1
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --cluster-cidr=10.244.0.0/16
      - --cluster-name=kubernetes
      - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      - --controllers=*,bootstrapsigner,tokencleaner
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      - --leader-elect=true
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --root-ca-file=/etc/kubernetes/pki/ca.crt
      - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --use-service-account-credentials=true
      image: registry.k8s.io/kube-controller-manager:v1.26.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/pki
        name: etc-pki
        readOnly: true
      - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        name: flexvolume-dir
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8s-master
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: etc-pki
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        type: DirectoryOrCreate
      name: flexvolume-dir
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:52:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:52:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:52:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:52:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://9f9b8a319c5cc13ecf7766caad5ebb9fd09b29fcd98c894d22be8945e8d66aae
      image: registry.k8s.io/kube-controller-manager:v1.26.2
      imageID: registry.k8s.io/kube-controller-manager@sha256:5434d52f88eb16bc5e98ccb65e97e97cb5cf7861749afbf26174d27c4ece1fad
      lastState: {}
      name: kube-controller-manager
      ready: true
      restartCount: 4
      started: true
      state:
        running:
          startedAt: "2023-04-06T05:52:36Z"
    hostIP: 192.168.118.238
    phase: Running
    podIP: 192.168.118.238
    podIPs:
    - ip: 192.168.118.238
    qosClass: Burstable
    startTime: "2023-04-06T05:52:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-03-14T08:48:55Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 6646d95c56
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-5gzhx
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: 300bbd2a-e5ab-49a4-ba87-2dd714110394
    resourceVersion: "72520"
    uid: d4d0c19a-fcd8-470a-a17b-f73a6b72817c
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - k8s-node1
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.26.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jmlmz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8s-node1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-jmlmz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:48:56Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:49:35Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:49:35Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:48:55Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://591eaebb1bf763834a6d6c5b661e28afa768e63e21c41d9a1deedcce2848af29
      image: registry.k8s.io/kube-proxy:v1.26.2
      imageID: registry.k8s.io/kube-proxy@sha256:5dac6611aceb1452a5d4036108a15ceb0699c083a942977e30640d521e7d2078
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-03-14T08:49:34Z"
    hostIP: 192.168.118.239
    phase: Running
    podIP: 192.168.118.239
    podIPs:
    - ip: 192.168.118.239
    qosClass: BestEffort
    startTime: "2023-03-14T08:48:56Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-03-14T08:32:11Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 6646d95c56
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-m6cf4
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: 300bbd2a-e5ab-49a4-ba87-2dd714110394
    resourceVersion: "72384"
    uid: c8f8f222-ec97-4661-b485-1971ae6f6032
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - k8s-master
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.26.2
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-sdqfw
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8s-master
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-sdqfw
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:32:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-03-14T08:32:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://5065c3ca3499f57f33b73664267593f63ca17e4b184ca24dc79f32e48149d7f5
      image: registry.k8s.io/kube-proxy:v1.26.2
      imageID: registry.k8s.io/kube-proxy@sha256:5dac6611aceb1452a5d4036108a15ceb0699c083a942977e30640d521e7d2078
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2023-04-06T05:53:18Z"
    hostIP: 192.168.118.238
    phase: Running
    podIP: 192.168.118.238
    podIPs:
    - ip: 192.168.118.238
    qosClass: BestEffort
    startTime: "2023-03-14T08:32:11Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 360220c29102c5d4ce4c9c9182591b1e
      kubernetes.io/config.mirror: 360220c29102c5d4ce4c9c9182591b1e
      kubernetes.io/config.seen: "2023-03-14T16:31:59.547648655+08:00"
      kubernetes.io/config.source: file
    creationTimestamp: "2023-03-14T08:32:00Z"
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-k8s-master
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: k8s-master
      uid: 73b10b46-027c-4c34-97c3-caacea2fbd8e
    resourceVersion: "72394"
    uid: d393d991-d371-4511-917b-12a144393162
  spec:
    containers:
    - command:
      - kube-scheduler
      - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
      - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
      - --bind-address=127.0.0.1
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      - --leader-elect=true
      image: registry.k8s.io/kube-scheduler:v1.26.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8s-master
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:52:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:04Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:53:04Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-04-06T05:52:30Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://acd5e29d365e5f75dbe019149fbe3366bf8a60b2efdf5037364070270bb0604a
      image: registry.k8s.io/kube-scheduler:v1.26.2
      imageID: registry.k8s.io/kube-scheduler@sha256:78ce2dc8099431b72acbf4c0000b65b67a6fa082d3ce4050c8d836a66d2e428c
      lastState: {}
      name: kube-scheduler
      ready: true
      restartCount: 4
      started: true
      state:
        running:
          startedAt: "2023-04-06T05:52:37Z"
    hostIP: 192.168.118.238
    phase: Running
    podIP: 192.168.118.238
    podIPs:
    - ip: 192.168.118.238
    qosClass: Burstable
    startTime: "2023-04-06T05:52:30Z"
kind: List
metadata:
  resourceVersion: ""
