apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2022-01-18T06:00:16Z"
    generateName: coredns-558bd4d5db-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 558bd4d5db
    name: coredns-558bd4d5db-blprt
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-558bd4d5db
      uid: 909485f5-663e-486f-8012-4a91e4395540
    resourceVersion: "946"
    uid: 69c40aa2-f202-4388-abe3-b94007f63494
  spec:
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: k8s.gcr.io/coredns/coredns:v1.8.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-2fnfn
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: k8smaster
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-2fnfn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:56Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:58Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:58Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:55Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://e0893d6657beb5baff546e4b3310b3a22b67363fabccc85a5aa343faeddc74e5
      image: k8s.gcr.io/coredns/coredns:v1.8.0
      imageID: docker-pullable://k8s.gcr.io/coredns/coredns@sha256:cc8fb77bc2a0541949d1d9320a641b82fd392b0d3d8145469ca4709ae769980e
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-01-18T06:05:58Z"
    hostIP: 192.168.118.209
    phase: Running
    podIP: 10.244.0.2
    podIPs:
    - ip: 10.244.0.2
    qosClass: Burstable
    startTime: "2022-01-18T06:05:56Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2022-01-18T06:00:16Z"
    generateName: coredns-558bd4d5db-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 558bd4d5db
    name: coredns-558bd4d5db-nqxnp
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-558bd4d5db
      uid: 909485f5-663e-486f-8012-4a91e4395540
    resourceVersion: "953"
    uid: a5f24f97-3410-4d67-97d7-ae013ef5527d
  spec:
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: k8s.gcr.io/coredns/coredns:v1.8.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4ftf6
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: k8smaster
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-4ftf6
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:58Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:58Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:55Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ee7ec5161833e30f3758a995c6ffc3b830c95026e2ce072ef325537ca7a014c2
      image: k8s.gcr.io/coredns/coredns:v1.8.0
      imageID: docker-pullable://k8s.gcr.io/coredns/coredns@sha256:cc8fb77bc2a0541949d1d9320a641b82fd392b0d3d8145469ca4709ae769980e
      lastState: {}
      name: coredns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-01-18T06:05:58Z"
    hostIP: 192.168.118.209
    phase: Running
    podIP: 10.244.0.3
    podIPs:
    - ip: 10.244.0.3
    qosClass: Burstable
    startTime: "2022-01-18T06:05:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/etcd.advertise-client-urls: https://192.168.118.209:2379
      kubernetes.io/config.hash: efdbef2616b75981814bf82fbcde3b90
      kubernetes.io/config.mirror: efdbef2616b75981814bf82fbcde3b90
      kubernetes.io/config.seen: "2022-01-18T06:00:02.521260804Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2022-01-18T06:00:09Z"
    labels:
      component: etcd
      tier: control-plane
    name: etcd-k8smaster
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: k8smaster
      uid: 50d99347-fa76-4fb8-93b1-70aced6b0369
    resourceVersion: "482"
    uid: f9d5210f-e0cd-4b6f-ac74-6af8a69c7962
  spec:
    containers:
    - command:
      - etcd
      - --advertise-client-urls=https://192.168.118.209:2379
      - --cert-file=/etc/kubernetes/pki/etcd/server.crt
      - --client-cert-auth=true
      - --data-dir=/var/lib/etcd
      - --initial-advertise-peer-urls=https://192.168.118.209:2380
      - --initial-cluster=k8smaster=https://192.168.118.209:2380
      - --key-file=/etc/kubernetes/pki/etcd/server.key
      - --listen-client-urls=https://127.0.0.1:2379,https://192.168.118.209:2379
      - --listen-metrics-urls=http://127.0.0.1:2381
      - --listen-peer-urls=https://192.168.118.209:2380
      - --name=k8smaster
      - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
      - --peer-client-cert-auth=true
      - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
      - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      - --snapshot-count=10000
      - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      image: k8s.gcr.io/etcd:3.4.13-0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /health
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/etcd
        name: etcd-data
      - mountPath: /etc/kubernetes/pki/etcd
        name: etcd-certs
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8smaster
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki/etcd
        type: DirectoryOrCreate
      name: etcd-certs
    - hostPath:
        path: /var/lib/etcd
        type: DirectoryOrCreate
      name: etcd-data
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:15Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:15Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://bb3c9227211224e03fa8d035199eae480c1e81505b27f22be7b187df98103b3d
      image: k8s.gcr.io/etcd:3.4.13-0
      imageID: docker-pullable://k8s.gcr.io/etcd@sha256:4ad90a11b55313b182afc186b9876c8e891531b8db4c9bf1541953021618d0e2
      lastState: {}
      name: etcd
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-01-18T05:59:34Z"
    hostIP: 192.168.118.209
    phase: Running
    podIP: 192.168.118.209
    podIPs:
    - ip: 192.168.118.209
    qosClass: Burstable
    startTime: "2022-01-18T06:00:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 192.168.118.209:6443
      kubernetes.io/config.hash: a09cdbe77956fc966fdad92ec6fa0195
      kubernetes.io/config.mirror: a09cdbe77956fc966fdad92ec6fa0195
      kubernetes.io/config.seen: "2022-01-18T06:00:02.521312046Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2022-01-18T06:00:09Z"
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-k8smaster
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: k8smaster
      uid: 50d99347-fa76-4fb8-93b1-70aced6b0369
    resourceVersion: "480"
    uid: 0fc139c0-a6be-4f3e-b0d2-12bfdaba2536
  spec:
    containers:
    - command:
      - kube-apiserver
      - --advertise-address=192.168.118.209
      - --allow-privileged=true
      - --authorization-mode=Node,RBAC
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --enable-admission-plugins=NodeRestriction
      - --enable-bootstrap-token-auth=true
      - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
      - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
      - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
      - --etcd-servers=https://127.0.0.1:2379
      - --insecure-port=0
      - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      - --requestheader-allowed-names=front-proxy-client
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --secure-port=6443
      - --service-account-issuer=https://kubernetes.default.svc.cluster.local
      - --service-account-key-file=/etc/kubernetes/pki/sa.pub
      - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      image: k8s.gcr.io/kube-apiserver:v1.21.8
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 192.168.118.209
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: 192.168.118.209
          path: /readyz
          port: 6443
          scheme: HTTPS
        periodSeconds: 1
        successThreshold: 1
        timeoutSeconds: 15
      resources:
        requests:
          cpu: 250m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 192.168.118.209
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/pki
        name: etc-pki
        readOnly: true
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8smaster
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: etc-pki
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://7a33ec2fc3fad961bbd7dd4cd70e4258026581124a82700f5ef805dc90159b3a
      image: k8s.gcr.io/kube-apiserver:v1.21.8
      imageID: docker-pullable://k8s.gcr.io/kube-apiserver@sha256:303737086912d90434bae8d696dd6b5aa3cf4e45301d8e9e5bc57a20871d240a
      lastState: {}
      name: kube-apiserver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-01-18T05:59:44Z"
    hostIP: 192.168.118.209
    phase: Running
    podIP: 192.168.118.209
    podIPs:
    - ip: 192.168.118.209
    qosClass: Burstable
    startTime: "2022-01-18T06:00:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 265a5efa235ea0bbe0a61ced872ee5d3
      kubernetes.io/config.mirror: 265a5efa235ea0bbe0a61ced872ee5d3
      kubernetes.io/config.seen: "2022-01-18T06:00:02.521325636Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2022-01-18T06:00:09Z"
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-k8smaster
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: k8smaster
      uid: 50d99347-fa76-4fb8-93b1-70aced6b0369
    resourceVersion: "483"
    uid: 072db43b-1a5c-4894-bb93-c504021a4f26
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --allocate-node-cidrs=true
      - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --bind-address=127.0.0.1
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --cluster-cidr=10.244.0.0/16
      - --cluster-name=kubernetes
      - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      - --controllers=*,bootstrapsigner,tokencleaner
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      - --leader-elect=true
      - --port=0
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --root-ca-file=/etc/kubernetes/pki/ca.crt
      - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --use-service-account-credentials=true
      image: k8s.gcr.io/kube-controller-manager:v1.21.8
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/pki
        name: etc-pki
        readOnly: true
      - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        name: flexvolume-dir
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8smaster
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: etc-pki
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        type: DirectoryOrCreate
      name: flexvolume-dir
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:11Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:11Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://e5a37b53ea686295f79280997eca64eea5ca33800b7e8475808603374ca6fdd3
      image: k8s.gcr.io/kube-controller-manager:v1.21.8
      imageID: docker-pullable://k8s.gcr.io/kube-controller-manager@sha256:0d131bc6459d41b2efc485305dbbf7c4480f0cd314b65e655722171f81b73abc
      lastState: {}
      name: kube-controller-manager
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-01-18T06:00:00Z"
    hostIP: 192.168.118.209
    phase: Running
    podIP: 192.168.118.209
    podIPs:
    - ip: 192.168.118.209
    qosClass: Burstable
    startTime: "2022-01-18T06:00:09Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2022-01-18T06:05:04Z"
    generateName: kube-flannel-ds-
    labels:
      app: flannel
      controller-revision-hash: 85cb499978
      pod-template-generation: "1"
      tier: node
    name: kube-flannel-ds-6hs6k
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-flannel-ds
      uid: a94876be-45e5-4a91-ae7f-66926e217bde
    resourceVersion: "893"
    uid: 06c018ea-db5b-4884-8658-babb50f34f6f
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - k8smaster
    containers:
    - args:
      - --ip-masq
      - --kube-subnet-mgr
      command:
      - /opt/bin/flanneld
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/mirrored-flannelcni-flannel:v0.16.1
      imagePullPolicy: IfNotPresent
      name: kube-flannel
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /run/flannel
        name: run
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pcwdq
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - args:
      - -f
      - /flannel
      - /opt/cni/bin/flannel
      command:
      - cp
      image: rancher/mirrored-flannelcni-flannel-cni-plugin:v1.0.0
      imagePullPolicy: IfNotPresent
      name: install-cni-plugin
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-plugin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pcwdq
        readOnly: true
    - args:
      - -f
      - /etc/kube-flannel/cni-conf.json
      - /etc/cni/net.d/10-flannel.conflist
      command:
      - cp
      image: rancher/mirrored-flannelcni-flannel:v0.16.1
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pcwdq
        readOnly: true
    nodeName: k8smaster
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: flannel
    serviceAccountName: flannel
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /run/flannel
        type: ""
      name: run
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-plugin
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni
    - configMap:
        defaultMode: 420
        name: kube-flannel-cfg
      name: flannel-cfg
    - name: kube-api-access-pcwdq
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:31Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:31Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:05:04Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://4e526cefefddd374122fddff80377469e0dc913ad3206ab77ac432b5f9cdceae
      image: rancher/mirrored-flannelcni-flannel:v0.16.1
      imageID: docker-pullable://rancher/mirrored-flannelcni-flannel@sha256:c2965afde3cf75b89d280f3263151fcd4e58a5901885bef18e1ebfbeef69801e
      lastState: {}
      name: kube-flannel
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-01-18T06:05:31Z"
    hostIP: 192.168.118.209
    initContainerStatuses:
    - containerID: docker://766b8636365604a79a451180dde92d73c7e2fdfa12b9c78f83f0e922a09859d6
      image: rancher/mirrored-flannelcni-flannel-cni-plugin:v1.0.0
      imageID: docker-pullable://rancher/mirrored-flannelcni-flannel-cni-plugin@sha256:bfe8f30c74bc6f31eba0cc6659e396dbdd5ab171314ed542cc238ae046660ede
      lastState: {}
      name: install-cni-plugin
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://766b8636365604a79a451180dde92d73c7e2fdfa12b9c78f83f0e922a09859d6
          exitCode: 0
          finishedAt: "2022-01-18T06:05:15Z"
          reason: Completed
          startedAt: "2022-01-18T06:05:15Z"
    - containerID: docker://07243aeb0613a1e37b07f1e8ed344982d7bb9d26b37ddf8060c394a5a5514fda
      image: rancher/mirrored-flannelcni-flannel:v0.16.1
      imageID: docker-pullable://rancher/mirrored-flannelcni-flannel@sha256:c2965afde3cf75b89d280f3263151fcd4e58a5901885bef18e1ebfbeef69801e
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://07243aeb0613a1e37b07f1e8ed344982d7bb9d26b37ddf8060c394a5a5514fda
          exitCode: 0
          finishedAt: "2022-01-18T06:05:29Z"
          reason: Completed
          startedAt: "2022-01-18T06:05:29Z"
    phase: Running
    podIP: 192.168.118.209
    podIPs:
    - ip: 192.168.118.209
    qosClass: Burstable
    startTime: "2022-01-18T06:05:04Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2022-01-18T06:07:21Z"
    generateName: kube-flannel-ds-
    labels:
      app: flannel
      controller-revision-hash: 85cb499978
      pod-template-generation: "1"
      tier: node
    name: kube-flannel-ds-d2zcj
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-flannel-ds
      uid: a94876be-45e5-4a91-ae7f-66926e217bde
    resourceVersion: "1169"
    uid: cc18ef15-d977-4302-bf4d-2162252317a3
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - k8snode1
    containers:
    - args:
      - --ip-masq
      - --kube-subnet-mgr
      command:
      - /opt/bin/flanneld
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: rancher/mirrored-flannelcni-flannel:v0.16.1
      imagePullPolicy: IfNotPresent
      name: kube-flannel
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /run/flannel
        name: run
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vkr9w
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - args:
      - -f
      - /flannel
      - /opt/cni/bin/flannel
      command:
      - cp
      image: rancher/mirrored-flannelcni-flannel-cni-plugin:v1.0.0
      imagePullPolicy: IfNotPresent
      name: install-cni-plugin
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/cni/bin
        name: cni-plugin
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vkr9w
        readOnly: true
    - args:
      - -f
      - /etc/kube-flannel/cni-conf.json
      - /etc/cni/net.d/10-flannel.conflist
      command:
      - cp
      image: rancher/mirrored-flannelcni-flannel:v0.16.1
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni
      - mountPath: /etc/kube-flannel/
        name: flannel-cfg
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vkr9w
        readOnly: true
    nodeName: k8snode1
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: flannel
    serviceAccountName: flannel
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /run/flannel
        type: ""
      name: run
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-plugin
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni
    - configMap:
        defaultMode: 420
        name: kube-flannel-cfg
      name: flannel-cfg
    - name: kube-api-access-vkr9w
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:08:07Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:08:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:08:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:07:21Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ee9ffe5ad9d6ec85e68257abf49dcd5c70b09f5f054acbe990b4e71810e199ea
      image: rancher/mirrored-flannelcni-flannel:v0.16.1
      imageID: docker-pullable://rancher/mirrored-flannelcni-flannel@sha256:c2965afde3cf75b89d280f3263151fcd4e58a5901885bef18e1ebfbeef69801e
      lastState: {}
      name: kube-flannel
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-01-18T06:08:08Z"
    hostIP: 192.168.118.208
    initContainerStatuses:
    - containerID: docker://500be0ef5a505f231a426608aa344b95ab2927da56f7e4c4d7026bd6f6cf551e
      image: rancher/mirrored-flannelcni-flannel-cni-plugin:v1.0.0
      imageID: docker-pullable://rancher/mirrored-flannelcni-flannel-cni-plugin@sha256:bfe8f30c74bc6f31eba0cc6659e396dbdd5ab171314ed542cc238ae046660ede
      lastState: {}
      name: install-cni-plugin
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://500be0ef5a505f231a426608aa344b95ab2927da56f7e4c4d7026bd6f6cf551e
          exitCode: 0
          finishedAt: "2022-01-18T06:07:51Z"
          reason: Completed
          startedAt: "2022-01-18T06:07:51Z"
    - containerID: docker://50b6bcf0eab44ad1b19d65b8de98fced508e5be68db4b40157c9effb2814ead7
      image: rancher/mirrored-flannelcni-flannel:v0.16.1
      imageID: docker-pullable://rancher/mirrored-flannelcni-flannel@sha256:c2965afde3cf75b89d280f3263151fcd4e58a5901885bef18e1ebfbeef69801e
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      state:
        terminated:
          containerID: docker://50b6bcf0eab44ad1b19d65b8de98fced508e5be68db4b40157c9effb2814ead7
          exitCode: 0
          finishedAt: "2022-01-18T06:08:06Z"
          reason: Completed
          startedAt: "2022-01-18T06:08:06Z"
    phase: Running
    podIP: 192.168.118.208
    podIPs:
    - ip: 192.168.118.208
    qosClass: Burstable
    startTime: "2022-01-18T06:07:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2022-01-18T06:00:16Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 7546c69d65
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-7rsmf
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: ec8698b0-646f-414c-8029-94aa0cf5530a
    resourceVersion: "472"
    uid: f0643178-da5c-459b-acec-1ebac8cfc113
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - k8smaster
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: k8s.gcr.io/kube-proxy:v1.21.8
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dnrkk
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8smaster
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-dnrkk
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:16Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:16Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://e856a8c94cfe11bdaa85dcbb9478eedfa1e11284e7344d5f2bc0f94756ded3ab
      image: k8s.gcr.io/kube-proxy:v1.21.8
      imageID: docker-pullable://k8s.gcr.io/kube-proxy@sha256:d5334eee53a3f0ddff4588b25e7e7f5bbd96b9a728eee0ae1a19c0e1b23c29d5
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-01-18T06:00:17Z"
    hostIP: 192.168.118.209
    phase: Running
    podIP: 192.168.118.209
    podIPs:
    - ip: 192.168.118.209
    qosClass: BestEffort
    startTime: "2022-01-18T06:00:16Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2022-01-18T06:07:21Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 7546c69d65
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-fx9mp
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: ec8698b0-646f-414c-8029-94aa0cf5530a
    resourceVersion: "1122"
    uid: e58ee087-3a7d-44af-8990-9ce037f4019e
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - k8snode1
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: k8s.gcr.io/kube-proxy:v1.21.8
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-967rp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8snode1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-967rp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:07:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:07:43Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:07:43Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:07:21Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://d66f76587a0781bd7131dab7df6f04ef9e5d027c4ffd2bced6c81b6e154a4f0a
      image: k8s.gcr.io/kube-proxy:v1.21.8
      imageID: docker-pullable://k8s.gcr.io/kube-proxy@sha256:d5334eee53a3f0ddff4588b25e7e7f5bbd96b9a728eee0ae1a19c0e1b23c29d5
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-01-18T06:07:43Z"
    hostIP: 192.168.118.208
    phase: Running
    podIP: 192.168.118.208
    podIPs:
    - ip: 192.168.118.208
    qosClass: BestEffort
    startTime: "2022-01-18T06:07:23Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 70dd9857b8fe2ded4b34a2d05a0bec32
      kubernetes.io/config.mirror: 70dd9857b8fe2ded4b34a2d05a0bec32
      kubernetes.io/config.seen: "2022-01-18T06:00:02.521338284Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2022-01-18T06:00:09Z"
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-k8smaster
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: k8smaster
      uid: 50d99347-fa76-4fb8-93b1-70aced6b0369
    resourceVersion: "500"
    uid: 4062723d-52d1-43d6-b050-42ad0c6b095a
  spec:
    containers:
    - command:
      - kube-scheduler
      - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
      - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
      - --bind-address=127.0.0.1
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      - --leader-elect=true
      - --port=0
      image: k8s.gcr.io/kube-scheduler:v1.21.8
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: k8smaster
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:09Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:29Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:29Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2022-01-18T06:00:09Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://f5efb7da740317f1dc4606f428fb4dfaa70f56c68d3acd9ec1c7914fdb63c6a7
      image: k8s.gcr.io/kube-scheduler:v1.21.8
      imageID: docker-pullable://k8s.gcr.io/kube-scheduler@sha256:4330e60b27af54d911608d0b8e4f1b96dd3cb8817fd6d4d6f0de409c356d538e
      lastState: {}
      name: kube-scheduler
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2022-01-18T06:00:10Z"
    hostIP: 192.168.118.209
    phase: Running
    podIP: 192.168.118.209
    podIPs:
    - ip: 192.168.118.209
    qosClass: Burstable
    startTime: "2022-01-18T06:00:09Z"
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
